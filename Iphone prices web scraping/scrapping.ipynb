{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start url & scraping date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = 'https://asgoodasnew.de/Handys/Apple/iPhone-14/'\n",
    "scrap_date = datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_url(url):\n",
    "\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pages(soup):\n",
    "\n",
    "    n_sites = np.int(np.trunc(np.int(soup.find('div', class_='listlocator-articlecount pull-left').text.strip().replace(' Artikel', '')) / 12) + 1)\n",
    "    return n_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agan_main_url(url, add):\n",
    "    url = f'{url}?pgNr={add}'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_name(soup):\n",
    "    models = soup.find_all('div', class_='listitem-title')\n",
    "\n",
    "    models_mod = []\n",
    "    \n",
    "    for model in models:\n",
    "        model = model.text.strip()\n",
    "\n",
    "        models_mod.append(model)\n",
    "\n",
    "    return models_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agan_model_url(model_name):\n",
    "\n",
    "    #model_add = model_name.replace(' ', '-')\n",
    "\n",
    "    model_url = f\"{start_url}{model_name.replace(' ','-')}.html\"\n",
    "\n",
    "    return model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_conditions(soup):\n",
    "    conditions = soup.find_all('div', class_='btn-radio')\n",
    "\n",
    "    conditions_mod = []\n",
    "    status = []\n",
    "\n",
    "    for condition in conditions:\n",
    "        condition = condition.label.text.strip().split('\\n')\n",
    "\n",
    "        if len(condition) == 2:\n",
    "            conditions_mod.append(condition[0])\n",
    "            status.append(condition[1].strip())\n",
    "        else:\n",
    "            conditions_mod.append(condition[0])\n",
    "            status.append('verfügbar')\n",
    "        \n",
    "    return conditions_mod, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_prices(soup):\n",
    "    prices = soup.find_all('div', class_='conditions-price')\n",
    "\n",
    "    old_prices = []\n",
    "    new_prices = []\n",
    "\n",
    "    for price in prices:\n",
    "        old_price = np.int(price.text.strip()[:4].replace(',', ''))\n",
    "        new_price = price.find('div', class_='conditions--newprice').text.strip()[:-3]\n",
    "\n",
    "        if new_price == '':\n",
    "            new_price = 0\n",
    "        else: new_price = np.int(new_price)\n",
    "\n",
    "        old_prices.append(old_price)\n",
    "        new_prices.append(new_price)\n",
    "    \n",
    "    return old_prices, new_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_specs(soup):\n",
    "    attr_vals = soup.find('td', attrs={'class':\"datasheet_cell td_value td_1er td_02 td-6\",\n",
    "                                    'datag':\"grp_23\",\n",
    "                                    'datak':\"kat_469\"}).text.strip().split('x')\n",
    "\n",
    "    attr_val_2 = []\n",
    "\n",
    "    for attr_val in attr_vals:    \n",
    "\n",
    "        attr_val = float(attr_val.replace('mm', '').strip().replace(',', '.'))\n",
    "        attr_val_2.append(attr_val)\n",
    "\n",
    "    return attr_val_2[0], attr_val_2[1], attr_val_2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_list():\n",
    "\n",
    "    soup = scrap_url(start_url)\n",
    "    n_sites = count_pages(soup)\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for i in range(n_sites):\n",
    "\n",
    "        url = create_agan_main_url(start_url, i)\n",
    "\n",
    "        soup = scrap_url(url)\n",
    "\n",
    "        models.append(read_model_name(soup))\n",
    "\n",
    "        #if soup.find('li', class_='next disabled') != None:\n",
    "            #break\n",
    "\n",
    "    models = [model for model_list in models for model in model_list]\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spec_model_url(model_name):\n",
    "\n",
    "    models_adj = model_name.split()[:-2]\n",
    "\n",
    "    new_model_name = []\n",
    "    sizes = ['GB', 'TB']\n",
    "\n",
    "    for m in models_adj:\n",
    "        \n",
    "        if any([size in m for size in sizes]):\n",
    "            m = ''\n",
    "        \n",
    "        new_model_name.append(m.lower())\n",
    "\n",
    "    new_model = '-'.join(new_model_name)\n",
    "\n",
    "    model_url = f'https://www.inside-digital.de/handys/{new_model}'\n",
    "\n",
    "    return model_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_mod(df):\n",
    "\n",
    "    df['Datum'] = scrap_date\n",
    "    df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "\n",
    "    df['Rabatt'] = df.apply(lambda x: x['aktueller Preis'] - x['Preis'] \n",
    "                                            if x['aktueller Preis'] > 0 else 0, axis=1)\n",
    "\n",
    "    df = df[['Datum',\n",
    "            'Modell',\n",
    "            'Zustand',\n",
    "            'Status',\n",
    "            'Preis',\n",
    "            'aktueller Preis', \n",
    "            'Rabatt',\n",
    "            'Höhe',\n",
    "            'Breite',\n",
    "            'Tiefe'\n",
    "            ]]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scraped_data(model_list):\n",
    "\n",
    "    full_data = pd.DataFrame()\n",
    "\n",
    "    for model in model_list:\n",
    "\n",
    "        # scrape model prices\n",
    "        model_url_agan = create_agan_model_url(model)\n",
    "        soup = scrap_url(model_url_agan)\n",
    "\n",
    "        con, stat = read_model_conditions(soup)\n",
    "        old, new = read_model_prices(soup)\n",
    "\n",
    "        # scrape models specifications\n",
    "        model_url_spec = create_spec_model_url(model)\n",
    "\n",
    "        soup = scrap_url(model_url_spec)\n",
    "\n",
    "        height, width, depth = read_model_specs(soup)\n",
    "\n",
    "        # create DataFrame\n",
    "        data = pd.DataFrame(list(zip(con,stat, old, new)), \n",
    "                            columns =['Zustand', 'Status', 'Preis', 'aktueller Preis'])\n",
    "        data['Modell'] = model\n",
    "        data['Höhe'] = height\n",
    "        data['Breite'] = width\n",
    "        data['Tiefe'] = depth\n",
    "\n",
    "        full_data = pd.concat([full_data, data])\n",
    "\n",
    "    full_data = df_mod(full_data)\n",
    "\n",
    "    return full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(full_data):\n",
    "    export = input(f'Do you want do download the data to Excel? Press y or n or ESC: ')\n",
    "\n",
    "    while export.lower() not in ['y', 'n', '']:\n",
    "        export = input(f'Please enter a valid value? Press y or n or ESC: ')\n",
    "\n",
    "    if export.lower() == 'y':\n",
    "            \n",
    "            file = 'iphone asgoodasnew preise scraping.xlsx'\n",
    "            df = pd.read_excel(file)\n",
    "\n",
    "            last_date = df['Datum'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "            new_date = full_data['Datum'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "            if new_date != last_date:\n",
    "\n",
    "                df_new = pd.concat([df, full_data])\n",
    "                df_new.to_excel(file, index=False)\n",
    "\n",
    "                print('Neue Daten exportiert')\n",
    "            \n",
    "            else:\n",
    "                print('Daten bereits vorhanden. Daten werden nicht exportiert.')\n",
    "    else:\n",
    "        print('Daten werden nicht exportiert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model_list = create_model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "full_data = create_scraped_data(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten werden nicht exportiert\n"
     ]
    }
   ],
   "source": [
    "export_data(full_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

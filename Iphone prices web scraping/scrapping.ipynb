{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start url & scraping date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = 'https://asgoodasnew.de/Handys/Apple/iPhone-14/'\n",
    "scrap_date = datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_url(url):\n",
    "\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pages(soup):\n",
    "\n",
    "    n_sites = int(np.trunc(int(soup.find('div', class_='listlocator-articlecount pull-left').text.strip().replace(' Artikel', '')) / 12) + 1)\n",
    "    return n_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agan_main_url(url, add):\n",
    "    url = f'{url}?pgNr={add}'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_name(soup):\n",
    "    models = soup.find_all('div', class_='listitem-title')\n",
    "\n",
    "    models_mod = []\n",
    "    \n",
    "    for model in models:\n",
    "        model = model.text.strip()\n",
    "\n",
    "        models_mod.append(model)\n",
    "\n",
    "    return models_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_list():\n",
    "\n",
    "    soup = scrap_url(start_url)\n",
    "    n_sites = count_pages(soup)\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for i in range(n_sites):\n",
    "\n",
    "        url = create_agan_main_url(start_url, i)\n",
    "\n",
    "        soup = scrap_url(url)\n",
    "\n",
    "        models.append(read_model_name(soup))\n",
    "\n",
    "        #if soup.find('li', class_='next disabled') != None:\n",
    "            #break\n",
    "\n",
    "    models = [model for model_list in models for model in model_list]\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agan_model_url(model_name):\n",
    "\n",
    "    #model_add = model_name.replace(' ', '-')\n",
    "\n",
    "    model_url = f\"{start_url}{model_name.replace(' ','-')}.html\"\n",
    "\n",
    "    return model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_conditions(soup):\n",
    "    conditions = soup.find_all('div', class_='btn-radio')\n",
    "\n",
    "    conditions_mod = []\n",
    "    status = []\n",
    "\n",
    "    for condition in conditions:\n",
    "        condition = condition.label.text.strip().split('\\n')\n",
    "\n",
    "        if len(condition) == 2:\n",
    "            conditions_mod.append(condition[0])\n",
    "            status.append(condition[1].strip())\n",
    "        else:\n",
    "            conditions_mod.append(condition[0])\n",
    "            status.append('verfÃ¼gbar')\n",
    "        \n",
    "    return conditions_mod, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_prices(soup):\n",
    "    prices = soup.find_all('div', class_='conditions-price')\n",
    "\n",
    "    old_prices = []\n",
    "    new_prices = []\n",
    "\n",
    "    for price in prices:\n",
    "        old_price = int(price.text.strip()[:4].replace(',', ''))\n",
    "        new_price = price.find('div', class_='conditions--newprice').text.strip()[:-3]\n",
    "\n",
    "        if new_price == '':\n",
    "            new_price = 0\n",
    "        else: new_price = int(new_price)\n",
    "\n",
    "        old_prices.append(old_price)\n",
    "        new_prices.append(new_price)\n",
    "    \n",
    "    return old_prices, new_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_attr(model):\n",
    "\n",
    "    model = model.split()\n",
    "\n",
    "    for number, item in enumerate(model):\n",
    "\n",
    "        brand = model[0]\n",
    "        product = model[1]\n",
    "        series = model[2]\n",
    "\n",
    "        if item.endswith(('GB', 'TB')):\n",
    "            size_index = number\n",
    "            size_str = model[size_index]\n",
    "\n",
    "            if size_str[-2:] == 'TB':\n",
    "                size_gb = int(size_str[:-2]) * 1000 + int(size_str[:-2]) * 24\n",
    "            else:\n",
    "                size_gb = size_str[:-2]\n",
    "\n",
    "            spec = ' '.join(model[3:size_index])\n",
    "            color = ' '.join(model[size_index + 1:])\n",
    "\n",
    "    return brand, product, series, spec, size_gb, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_specs(soup):\n",
    "    attr_vals = soup.find('td', attrs={'class':\"datasheet_cell td_value td_1er td_02 td-6\",\n",
    "                                    'datag':\"grp_23\",\n",
    "                                    'datak':\"kat_469\"}).text.strip().split('x')\n",
    "\n",
    "    attr_val_2 = []\n",
    "\n",
    "    for attr_val in attr_vals:    \n",
    "\n",
    "        attr_val = float(attr_val.replace('mm', '').strip().replace(',', '.'))\n",
    "        attr_val_2.append(attr_val)\n",
    "\n",
    "    return attr_val_2[0], attr_val_2[1], attr_val_2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spec_model_url(model_name):\n",
    "\n",
    "    models_adj = model_name.split()[:-2]\n",
    "\n",
    "    new_model_name = []\n",
    "    sizes = ['GB', 'TB']\n",
    "\n",
    "    for m in models_adj:\n",
    "        \n",
    "        if any([size in m for size in sizes]):\n",
    "            m = ''\n",
    "        \n",
    "        new_model_name.append(m.lower())\n",
    "\n",
    "    new_model = '-'.join(new_model_name)\n",
    "\n",
    "    model_url = f'https://www.inside-digital.de/handys/{new_model}'\n",
    "\n",
    "    return model_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_mod(df):\n",
    "\n",
    "    df['date'] = scrap_date\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    df['discount'] = df.apply(lambda x: x['cur_price'] - x['price'] \n",
    "                                            if x['cur_price'] > 0 else 0, axis=1)\n",
    "\n",
    "    df = df[['date',\n",
    "            'full_model_name',\n",
    "            'brand',\n",
    "            'product',\n",
    "            'series',\n",
    "            'specification',\n",
    "            'size_gb',\n",
    "            'color',\n",
    "            'condition',\n",
    "            'status',\n",
    "            'price',\n",
    "            'cur_price', \n",
    "            'discount',\n",
    "            'heigth',\n",
    "            'width',\n",
    "            'depth'\n",
    "            ]]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scraped_data(model_list):\n",
    "\n",
    "    full_data = pd.DataFrame()\n",
    "\n",
    "    for model in model_list:\n",
    "\n",
    "        # read model attributes\n",
    "        brand, product, series, spec, size_gb, color = create_model_attr(model)\n",
    "\n",
    "        # scrape model prices\n",
    "        model_url_agan = create_agan_model_url(model)\n",
    "        soup = scrap_url(model_url_agan)\n",
    "\n",
    "        con, stat = read_model_conditions(soup)\n",
    "        old, new = read_model_prices(soup)\n",
    "\n",
    "        # scrape models specifications\n",
    "        model_url_spec = create_spec_model_url(model)\n",
    "\n",
    "        soup = scrap_url(model_url_spec)\n",
    "\n",
    "        height, width, depth = read_model_specs(soup)\n",
    "\n",
    "        # create DataFrame\n",
    "        data = pd.DataFrame(list(zip(con,stat, old, new)), \n",
    "                            columns =['condition', 'status', 'price', 'cur_price'])\n",
    "        \n",
    "        data['full_model_name'] = model\n",
    "        data['brand'] = brand\n",
    "        data['product'] = product\n",
    "        data['series'] = series\n",
    "        data['specification'] = spec\n",
    "        data['size_gb'] = size_gb\n",
    "        data['color'] = color   \n",
    "        \n",
    "        data['heigth'] = height\n",
    "        data['width'] = width\n",
    "        data['depth'] = depth\n",
    "\n",
    "        full_data = pd.concat([full_data, data])\n",
    "\n",
    "    full_data = df_mod(full_data)\n",
    "\n",
    "    return full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(full_data):\n",
    "    export = input(f'Do you want do download the data to Excel? Press y or n or ESC: ')\n",
    "\n",
    "    while export.lower() not in ['y', 'n', '']:\n",
    "        export = input(f'Please enter a valid value? Press y or n or ESC: ')\n",
    "\n",
    "    if export.lower() == 'y':\n",
    "            \n",
    "            file = 'iphone asgoodasnew price scraping.xlsx'\n",
    "\n",
    "            try:\n",
    "                df = pd.read_excel(file)\n",
    "                last_date = df['date'].max().strftime('%Y-%m-%d')\n",
    "                new_date = full_data['date'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "                if new_date != last_date:\n",
    "                    df = pd.concat([df, full_data])\n",
    "                    df.to_excel(file, index=False)\n",
    "\n",
    "                    print('New records added to existing Excel file.')\n",
    "                \n",
    "                else:\n",
    "                    print('Records already existing in the file.')\n",
    "\n",
    "            except:\n",
    "                full_data.to_excel(file, index=False)\n",
    "                print('New records extracted and Excel file created.')\n",
    "            \n",
    "    else:\n",
    "        print('No records extracted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = create_model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = create_scraped_data(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records already existing in the file.\n"
     ]
    }
   ],
   "source": [
    "export_data(full_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
